We created a pod first in deployment kubectl apply -f kubia-deployment-v2.yaml
and then we created the service kubectl apply -f kubia-svc-nodeport.yaml
we can see we can ping it [root@ip-172-31-10-94 05-services]# curl 10.110.110.50:80
This is v2 running in pod kubia-7d5c456ffc-8wjrd

we see it is running, in case it is not running we can change the port in the nodeport.yaml and then try to apply this config and check










[root@ip-172-31-10-94 kubernetes-training]# cd 09-deployments/
[root@ip-172-31-10-94 09-deployments]# ls
kubia-deployment-and-service-v1.yaml  kubia-deployment-v2.yaml                      kubia-deployment-v3.yaml      v1  v3
kubia-deployment-v1.yaml              kubia-deployment-v3-with-readinesscheck.yaml  kubia-rc-and-service-v1.yaml  v2  v4
[root@ip-172-31-10-94 09-deployments]# kubectl apply -f kubia-deployment-v2.yaml
deployment.apps/kubia created
[root@ip-172-31-10-94 09-deployments]# kubectl get po
NAME                     READY   STATUS              RESTARTS   AGE
kubia-7d5c456ffc-8wjrd   0/1     ContainerCreating   0          4s
[root@ip-172-31-10-94 09-deployments]# kubectl get po -o wide
NAME                     READY   STATUS              RESTARTS   AGE   IP       NODE                                             NOMINATED NODE   READINESS GATES
kubia-7d5c456ffc-8wjrd   0/1     ContainerCreating   0          16s   <none>   ip-172-31-8-95.ap-southeast-1.compute.internal   <none>           <none>
[root@ip-172-31-10-94 09-deployments]# kubectl get po -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP                NODE                                             NOMINATED NODE   READINESS GATES
kubia-7d5c456ffc-8wjrd   1/1     Running   0          31s   192.168.105.189   ip-172-31-8-95.ap-southeast-1.compute.internal   <none>           <none>
[root@ip-172-31-10-94 09-deployments]# cd ..
[root@ip-172-31-10-94 kubernetes-training]# ls
00installation.md            05-services                09-deployments           16-dashboard           installation-multi-node-master.md
01-Getting-started           05-services.md             10 Stateful Set          16-dashboard-setup.md  Istio-setup.md
01gettingstartedWithKube.md  06-storage                 11-RBAC                  Deployments.md         Kubernetes-slides
03-Pods                      06-volumes.md              12-cluster-admintration  heapster.md            kubernetes-troubleshooting.md
03-pods.md                   07-configmap.md            13-networking            helm                   prometheus-setup.md
04-controllers               07-configmaps-and-secrets  14-security              history.txt            README.md
04-controllers.md            08-metadata                15-calico                ingress.md             Working with MiniKube.md
[root@ip-172-31-10-94 kubernetes-training]# cd 05-services/
[root@ip-172-31-10-94 05-services]# ls
external-service-endpoints.yaml     kubia-ingress.yaml                         kubia-svc-headless.yaml            kubia-svc-publish-not-ready.yaml
external-service-externalname.yaml  kubia-pod.yml                              kubia-svc-loadbalancer.yaml        kubia-svc.yaml
external-service.yaml               kubia-rc-readinessprobe.yaml               kubia-svc-named-ports.yaml         tls.cert
ingress                             kubia-replicaset.yaml                      kubia-svc-nodeport-onlylocal.yaml  tls.key
kubia-ingress-tls.yaml              kubia-svc-client-ip-session-affinity.yaml  kubia-svc-nodeport.yaml
[root@ip-172-31-10-94 05-services]# kubectl apply -f kubia-svc-nodeport.yaml
service/kubia-nodeport unchanged

[root@ip-172-31-10-94 05-services]# kubectl get svc
NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
kubernetes       ClusterIP   10.96.0.1       <none>        443/TCP        9m2s
kubia-nodeport   NodePort    10.110.110.50   <none>        80:30123/TCP   8m10s
[root@ip-172-31-10-94 05-services]# curl 10.110.110.50:80
This is v2 running in pod kubia-7d5c456ffc-8wjrd
[root@ip-172-31-10-94 05-services]# cat kubia-svc-nodeport.yaml
apiVersion: v1
kind: Service
metadata:
  name: kubia-nodeport
spec:
  type: NodePort
  ports:
  - port: 80
    targetPort: 8080
    nodePort: 30123
  selector:
    app: kubia

[root@ip-172-31-10-94 05-services]# cd ..
[root@ip-172-31-10-94 kubernetes-training]# cd 09-deployments/
[root@ip-172-31-10-94 09-deployments]# ls
kubia-deployment-and-service-v1.yaml  kubia-deployment-v2.yaml                      kubia-deployment-v3.yaml      v1  v3
kubia-deployment-v1.yaml              kubia-deployment-v3-with-readinesscheck.yaml  kubia-rc-and-service-v1.yaml  v2  v4
[root@ip-172-31-10-94 09-deployments]# cat kubia-deployment-v2.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  selector:
    matchLabels:
      app: kubia
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v2
        name: nodejs
[root@ip-172-31-10-94 09-deployments]# cd ..
[root@ip-172-31-10-94 kubernetes-training]# cd 05-services/
[root@ip-172-31-10-94 05-services]# ls
external-service-endpoints.yaml     kubia-ingress.yaml                         kubia-svc-headless.yaml            kubia-svc-publish-not-ready.yaml
external-service-externalname.yaml  kubia-pod.yml                              kubia-svc-loadbalancer.yaml        kubia-svc.yaml
external-service.yaml               kubia-rc-readinessprobe.yaml               kubia-svc-named-ports.yaml         tls.cert
ingress                             kubia-replicaset.yaml                      kubia-svc-nodeport-onlylocal.yaml  tls.key
kubia-ingress-tls.yaml              kubia-svc-client-ip-session-affinity.yaml  kubia-svc-nodeport.yaml
[root@ip-172-31-10-94 05-services]# cat kubia-pod.yml
apiVersion: v1
kind: Pod
metadata:
  name: kubiapod2
  labels:
    app: kubia
spec:
  containers:
  - image: luksa/kubia
    name: kubia
    ports:
    - containerPort: 8080
      protocol: TCP
[root@ip-172-31-10-94 05-services]# kubectl apply -f kubia-pod.yml
pod/kubiapod2 created
[root@ip-172-31-10-94 05-services]# kubectl get po
NAME                     READY   STATUS    RESTARTS   AGE
kubia-7d5c456ffc-8wjrd   1/1     Running   0          6m38s
kubiapod2                1/1     Running   0          11s
[root@ip-172-31-10-94 05-services]# kubectl get po -o wide
NAME                     READY   STATUS    RESTARTS   AGE     IP                NODE                                             NOMINATED NODE   READINESS GATES
kubia-7d5c456ffc-8wjrd   1/1     Running   0          6m49s   192.168.105.189   ip-172-31-8-95.ap-southeast-1.compute.internal   <none>           <none>
kubiapod2                1/1     Running   0          22s     192.168.105.190   ip-172-31-8-95.ap-southeast-1.compute.internal   <none>           <none>
[root@ip-172-31-10-94 05-services]#
